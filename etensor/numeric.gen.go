// Code generated by numeric.gen.go.tmpl. DO NOT EDIT.

// Copyright (c) 2019, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package etensor

import (
	"errors"
	"strconv"

	"github.com/apache/arrow/go/arrow"
	"github.com/apache/arrow/go/arrow/array"
	"github.com/apache/arrow/go/arrow/memory"
	"github.com/apache/arrow/go/arrow/tensor"
	"github.com/emer/emergent/bitslice"
	"github.com/goki/ki/ints"
	"github.com/goki/ki/kit"
)

// Int64 is an n-dim array of int64s.
type Int64 struct {
	Shape
	Values []int64
	Nulls  bitslice.Slice
}

// NewInt64 returns a new n-dimensional array of int64s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt64(shape, strides []int, names []string) *Int64 {
	tsr := &Int64{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int64, tsr.Len())
	return tsr
}

// NewInt64Shape returns a new n-dimensional array of int64s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewInt64Shape(shape *Shape) *Int64 {
	tsr := &Int64{}
	tsr.CopyShape(shape)
	tsr.Values = make([]int64, tsr.Len())
	return tsr
}

func (tsr *Int64) DataType() arrow.DataType { return &arrow.Int64Type{} }
func (tsr *Int64) Value(i []int) int64      { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int64) Set(i []int, val int64)   { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int64) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Int64) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Int64) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int64) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int64(val) }

func (tsr *Int64) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Int64) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int64(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Int64) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Int64) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Int64) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = int64(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int64) Clone() *Int64 {
	csr := NewInt64Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int64) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int64) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Int64) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int64) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Int64) SubSlice(subdim int, offs []int) (*Int64, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Int64{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int64{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int64) ToArrow() *tensor.Int64 {
	bld := array.NewInt64Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt64Array()
	return tensor.NewInt64(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int64) FromArrow(arw *tensor.Int64, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int64Values()
		tsr.Values = make([]int64, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int64Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Uint64 is an n-dim array of uint64s.
type Uint64 struct {
	Shape
	Values []uint64
	Nulls  bitslice.Slice
}

// NewUint64 returns a new n-dimensional array of uint64s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint64(shape, strides []int, names []string) *Uint64 {
	tsr := &Uint64{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint64, tsr.Len())
	return tsr
}

// NewUint64Shape returns a new n-dimensional array of uint64s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewUint64Shape(shape *Shape) *Uint64 {
	tsr := &Uint64{}
	tsr.CopyShape(shape)
	tsr.Values = make([]uint64, tsr.Len())
	return tsr
}

func (tsr *Uint64) DataType() arrow.DataType { return &arrow.Uint64Type{} }
func (tsr *Uint64) Value(i []int) uint64     { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint64) Set(i []int, val uint64)  { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint64) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Uint64) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Uint64) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint64) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint64(val) }

func (tsr *Uint64) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Uint64) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint64(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Uint64) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Uint64) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Uint64) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = uint64(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint64) Clone() *Uint64 {
	csr := NewUint64Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint64) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint64) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Uint64) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint64) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Uint64) SubSlice(subdim int, offs []int) (*Uint64, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Uint64{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint64{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint64) ToArrow() *tensor.Uint64 {
	bld := array.NewUint64Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint64Array()
	return tensor.NewUint64(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint64) FromArrow(arw *tensor.Uint64, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint64Values()
		tsr.Values = make([]uint64, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint64Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Float64 is an n-dim array of float64s.
type Float64 struct {
	Shape
	Values []float64
	Nulls  bitslice.Slice
}

// NewFloat64 returns a new n-dimensional array of float64s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewFloat64(shape, strides []int, names []string) *Float64 {
	tsr := &Float64{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]float64, tsr.Len())
	return tsr
}

// NewFloat64Shape returns a new n-dimensional array of float64s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewFloat64Shape(shape *Shape) *Float64 {
	tsr := &Float64{}
	tsr.CopyShape(shape)
	tsr.Values = make([]float64, tsr.Len())
	return tsr
}

func (tsr *Float64) DataType() arrow.DataType { return &arrow.Float64Type{} }
func (tsr *Float64) Value(i []int) float64    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Float64) Set(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Float64) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Float64) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Float64) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Float64) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = float64(val) }

func (tsr *Float64) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Float64) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = float64(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Float64) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Float64) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Float64) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = float64(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Float64) Clone() *Float64 {
	csr := NewFloat64Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Float64) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Float64) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Float64) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Float64) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Float64) SubSlice(subdim int, offs []int) (*Float64, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Float64{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Float64{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Float64) ToArrow() *tensor.Float64 {
	bld := array.NewFloat64Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewFloat64Array()
	return tensor.NewFloat64(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Float64) FromArrow(arw *tensor.Float64, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Float64Values()
		tsr.Values = make([]float64, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Float64Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Int32 is an n-dim array of int32s.
type Int32 struct {
	Shape
	Values []int32
	Nulls  bitslice.Slice
}

// NewInt32 returns a new n-dimensional array of int32s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt32(shape, strides []int, names []string) *Int32 {
	tsr := &Int32{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int32, tsr.Len())
	return tsr
}

// NewInt32Shape returns a new n-dimensional array of int32s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewInt32Shape(shape *Shape) *Int32 {
	tsr := &Int32{}
	tsr.CopyShape(shape)
	tsr.Values = make([]int32, tsr.Len())
	return tsr
}

func (tsr *Int32) DataType() arrow.DataType { return &arrow.Int32Type{} }
func (tsr *Int32) Value(i []int) int32      { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int32) Set(i []int, val int32)   { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int32) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Int32) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Int32) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int32) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int32(val) }

func (tsr *Int32) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Int32) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int32(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Int32) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Int32) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Int32) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = int32(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int32) Clone() *Int32 {
	csr := NewInt32Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int32) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int32) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Int32) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int32) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Int32) SubSlice(subdim int, offs []int) (*Int32, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Int32{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int32{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int32) ToArrow() *tensor.Int32 {
	bld := array.NewInt32Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt32Array()
	return tensor.NewInt32(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int32) FromArrow(arw *tensor.Int32, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int32Values()
		tsr.Values = make([]int32, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int32Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Uint32 is an n-dim array of uint32s.
type Uint32 struct {
	Shape
	Values []uint32
	Nulls  bitslice.Slice
}

// NewUint32 returns a new n-dimensional array of uint32s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint32(shape, strides []int, names []string) *Uint32 {
	tsr := &Uint32{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint32, tsr.Len())
	return tsr
}

// NewUint32Shape returns a new n-dimensional array of uint32s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewUint32Shape(shape *Shape) *Uint32 {
	tsr := &Uint32{}
	tsr.CopyShape(shape)
	tsr.Values = make([]uint32, tsr.Len())
	return tsr
}

func (tsr *Uint32) DataType() arrow.DataType { return &arrow.Uint32Type{} }
func (tsr *Uint32) Value(i []int) uint32     { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint32) Set(i []int, val uint32)  { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint32) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Uint32) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Uint32) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint32) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint32(val) }

func (tsr *Uint32) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Uint32) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint32(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Uint32) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Uint32) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Uint32) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = uint32(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint32) Clone() *Uint32 {
	csr := NewUint32Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint32) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint32) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Uint32) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint32) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Uint32) SubSlice(subdim int, offs []int) (*Uint32, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Uint32{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint32{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint32) ToArrow() *tensor.Uint32 {
	bld := array.NewUint32Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint32Array()
	return tensor.NewUint32(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint32) FromArrow(arw *tensor.Uint32, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint32Values()
		tsr.Values = make([]uint32, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint32Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Float32 is an n-dim array of float32s.
type Float32 struct {
	Shape
	Values []float32
	Nulls  bitslice.Slice
}

// NewFloat32 returns a new n-dimensional array of float32s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewFloat32(shape, strides []int, names []string) *Float32 {
	tsr := &Float32{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]float32, tsr.Len())
	return tsr
}

// NewFloat32Shape returns a new n-dimensional array of float32s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewFloat32Shape(shape *Shape) *Float32 {
	tsr := &Float32{}
	tsr.CopyShape(shape)
	tsr.Values = make([]float32, tsr.Len())
	return tsr
}

func (tsr *Float32) DataType() arrow.DataType { return &arrow.Float32Type{} }
func (tsr *Float32) Value(i []int) float32    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Float32) Set(i []int, val float32) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Float32) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Float32) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Float32) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Float32) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = float32(val) }

func (tsr *Float32) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Float32) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = float32(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Float32) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Float32) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Float32) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = float32(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Float32) Clone() *Float32 {
	csr := NewFloat32Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Float32) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Float32) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Float32) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Float32) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Float32) SubSlice(subdim int, offs []int) (*Float32, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Float32{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Float32{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Float32) ToArrow() *tensor.Float32 {
	bld := array.NewFloat32Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewFloat32Array()
	return tensor.NewFloat32(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Float32) FromArrow(arw *tensor.Float32, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Float32Values()
		tsr.Values = make([]float32, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Float32Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Int16 is an n-dim array of int16s.
type Int16 struct {
	Shape
	Values []int16
	Nulls  bitslice.Slice
}

// NewInt16 returns a new n-dimensional array of int16s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt16(shape, strides []int, names []string) *Int16 {
	tsr := &Int16{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int16, tsr.Len())
	return tsr
}

// NewInt16Shape returns a new n-dimensional array of int16s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewInt16Shape(shape *Shape) *Int16 {
	tsr := &Int16{}
	tsr.CopyShape(shape)
	tsr.Values = make([]int16, tsr.Len())
	return tsr
}

func (tsr *Int16) DataType() arrow.DataType { return &arrow.Int16Type{} }
func (tsr *Int16) Value(i []int) int16      { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int16) Set(i []int, val int16)   { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int16) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Int16) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Int16) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int16) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int16(val) }

func (tsr *Int16) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Int16) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int16(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Int16) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Int16) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Int16) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = int16(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int16) Clone() *Int16 {
	csr := NewInt16Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int16) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int16) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Int16) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int16) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Int16) SubSlice(subdim int, offs []int) (*Int16, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Int16{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int16{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int16) ToArrow() *tensor.Int16 {
	bld := array.NewInt16Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt16Array()
	return tensor.NewInt16(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int16) FromArrow(arw *tensor.Int16, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int16Values()
		tsr.Values = make([]int16, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int16Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Uint16 is an n-dim array of uint16s.
type Uint16 struct {
	Shape
	Values []uint16
	Nulls  bitslice.Slice
}

// NewUint16 returns a new n-dimensional array of uint16s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint16(shape, strides []int, names []string) *Uint16 {
	tsr := &Uint16{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint16, tsr.Len())
	return tsr
}

// NewUint16Shape returns a new n-dimensional array of uint16s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewUint16Shape(shape *Shape) *Uint16 {
	tsr := &Uint16{}
	tsr.CopyShape(shape)
	tsr.Values = make([]uint16, tsr.Len())
	return tsr
}

func (tsr *Uint16) DataType() arrow.DataType { return &arrow.Uint16Type{} }
func (tsr *Uint16) Value(i []int) uint16     { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint16) Set(i []int, val uint16)  { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint16) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Uint16) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Uint16) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint16) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint16(val) }

func (tsr *Uint16) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Uint16) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint16(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Uint16) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Uint16) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Uint16) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = uint16(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint16) Clone() *Uint16 {
	csr := NewUint16Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint16) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint16) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Uint16) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint16) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Uint16) SubSlice(subdim int, offs []int) (*Uint16, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Uint16{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint16{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint16) ToArrow() *tensor.Uint16 {
	bld := array.NewUint16Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint16Array()
	return tensor.NewUint16(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint16) FromArrow(arw *tensor.Uint16, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint16Values()
		tsr.Values = make([]uint16, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint16Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Int8 is an n-dim array of int8s.
type Int8 struct {
	Shape
	Values []int8
	Nulls  bitslice.Slice
}

// NewInt8 returns a new n-dimensional array of int8s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt8(shape, strides []int, names []string) *Int8 {
	tsr := &Int8{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int8, tsr.Len())
	return tsr
}

// NewInt8Shape returns a new n-dimensional array of int8s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewInt8Shape(shape *Shape) *Int8 {
	tsr := &Int8{}
	tsr.CopyShape(shape)
	tsr.Values = make([]int8, tsr.Len())
	return tsr
}

func (tsr *Int8) DataType() arrow.DataType { return &arrow.Int8Type{} }
func (tsr *Int8) Value(i []int) int8       { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int8) Set(i []int, val int8)    { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int8) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Int8) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Int8) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int8) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int8(val) }

func (tsr *Int8) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Int8) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int8(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Int8) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Int8) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Int8) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = int8(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int8) Clone() *Int8 {
	csr := NewInt8Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Int8) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int8) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Int8) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int8) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Int8) SubSlice(subdim int, offs []int) (*Int8, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Int8{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int8{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int8) ToArrow() *tensor.Int8 {
	bld := array.NewInt8Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt8Array()
	return tensor.NewInt8(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int8) FromArrow(arw *tensor.Int8, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int8Values()
		tsr.Values = make([]int8, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int8Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Uint8 is an n-dim array of uint8s.
type Uint8 struct {
	Shape
	Values []uint8
	Nulls  bitslice.Slice
}

// NewUint8 returns a new n-dimensional array of uint8s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint8(shape, strides []int, names []string) *Uint8 {
	tsr := &Uint8{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint8, tsr.Len())
	return tsr
}

// NewUint8Shape returns a new n-dimensional array of uint8s.
// Using shape structure instead of separate data.
// Nulls are initialized to nil.
func NewUint8Shape(shape *Shape) *Uint8 {
	tsr := &Uint8{}
	tsr.CopyShape(shape)
	tsr.Values = make([]uint8, tsr.Len())
	return tsr
}

func (tsr *Uint8) DataType() arrow.DataType { return &arrow.Uint8Type{} }
func (tsr *Uint8) Value(i []int) uint8      { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint8) Set(i []int, val uint8)   { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint8) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}
func (tsr *Uint8) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

func (tsr *Uint8) Float64Val(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint8) SetFloat64(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint8(val) }

func (tsr *Uint8) StringVal(i []int) string { j := tsr.Offset(i); return kit.ToString(tsr.Values[j]) }
func (tsr *Uint8) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint8(fv)
	}
}

// AggFloat64 applies given aggregation function to each element in the tensor, using float64
// conversions of the values.  init is the initial value for the agg variable.  returns final
// aggregate value
func (tsr *Uint8) AggFloat64(fun func(val float64, agg float64) float64, ini float64) float64 {
	ln := tsr.Len()
	ag := ini
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		ag = fun(val, ag)
	}
	return ag
}

// EvalFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and puts the results into given float64 slice, which is
// ensured to be of the proper length
func (tsr *Uint8) EvalFloat64(fun func(val float64) float64, res *[]float64) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		(*res)[j] = fun(val)
	}
}

// UpdtFloat64 applies given function to each element in the tensor, using float64
// conversions of the values, and writes the results back into the same tensor values
func (tsr *Uint8) UpdtFloat64(fun func(val float64) float64) {
	ln := tsr.Len()
	for j := 0; j < ln; j++ {
		val := float64(tsr.Values[j])
		tsr.Values[j] = uint8(fun(val))
	}
}

// Clone creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint8) Clone() *Uint8 {
	csr := NewUint8Shape(&tsr.Shape)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CloneTensor creates a new tensor that is a copy of the existing tensor, with its own
// separate memory -- changes to the clone will not affect the source.
func (tsr *Uint8) CloneTensor() Tensor {
	return tsr.Clone()
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint8) SetShape(shape, strides []int, names []string) {
	tsr.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// AddRows adds n rows (outer-most dimension) to RowMajor organized tensor.
func (tsr *Uint8) AddRows(n int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows, cells := tsr.RowCellSize()
	nln := (rows + n) * cells
	tsr.Shape.shape[0] += n
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint8) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = ints.MaxInt(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.shape[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
}

// SubSlice returns a new tensor as a sub-slice of the current one, incorporating the given number
// of dimensions (0 < subdim < NumDims of this tensor).  Only valid for row or column major layouts.
// subdim are the inner, contiguous dimensions (i.e., the final dims in RowMajor and the first ones in ColMajor).
// offs are offsets for the outer dimensions (len = NDims - subdim) for the subslice to return.
// The new tensor points to the values of the this tensor (i.e., modifications will affect both).
// Use Clone() method to separate the two.
// todo: not getting nulls yet.
func (tsr *Uint8) SubSlice(subdim int, offs []int) (*Uint8, error) {
	nd := tsr.NumDims()
	od := nd - subdim
	if od <= 0 {
		return nil, errors.New("SubSlice number of sub dimensions was >= NumDims -- must be less")
	}
	if tsr.IsRowMajor() {
		stsr := &Uint8{}
		stsr.SetShape(tsr.shape[od:], nil, tsr.names[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint8{}
		stsr.SetShape(tsr.shape[:subdim], nil, tsr.names[:subdim])
		stsr.strides = ColMajorStrides(stsr.shape)
		sti := make([]int, nd)
		for i := subdim; i < nd; i++ {
			sti[i] = offs[i-subdim]
		}
		stoff := tsr.Offset(sti)
		stsr.Values = tsr.Values[stoff:]
		return stsr, nil
	}
	return nil, errors.New("SubSlice only valid for RowMajor or ColMajor tensors")
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint8) ToArrow() *tensor.Uint8 {
	bld := array.NewUint8Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint8Array()
	return tensor.NewUint8(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint8) FromArrow(arw *tensor.Uint8, cpy bool) {
	nms := make([]string, arw.NumDims()) // todo: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint8Values()
		tsr.Values = make([]uint8, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint8Values()
	}
	// todo: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

func New(dtype arrow.Type, shape, strides []int, names []string) Tensor {
	switch dtype {
	case arrow.INT64:
		return NewInt64(shape, strides, names)
	case arrow.UINT64:
		return NewUint64(shape, strides, names)
	case arrow.FLOAT64:
		return NewFloat64(shape, strides, names)
	case arrow.INT32:
		return NewInt32(shape, strides, names)
	case arrow.UINT32:
		return NewUint32(shape, strides, names)
	case arrow.FLOAT32:
		return NewFloat32(shape, strides, names)
	case arrow.INT16:
		return NewInt16(shape, strides, names)
	case arrow.UINT16:
		return NewUint16(shape, strides, names)
	case arrow.INT8:
		return NewInt8(shape, strides, names)
	case arrow.UINT8:
		return NewUint8(shape, strides, names)
	case arrow.STRING:
		return NewString(shape, strides, names)
	case arrow.BOOL:
		return NewBits(shape, strides, names)
	}
	return nil
}
